{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae8ecc14",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dl_players'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msys\u001b[39;00m\n\u001b[32m      2\u001b[39m sys.path.append(\u001b[33m'\u001b[39m\u001b[33m../onitama/\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtrainer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RegularDataTrainer\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdl_players_v3\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CNNPlayer_v3\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/python/onitama-rl/notebooks/../onitama/trainer.py:5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mconstants\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mboard\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Board\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgame\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Game, GameSession\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpickle\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/python/onitama-rl/notebooks/../onitama/game.py:7\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcard\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Card\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplayers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Player, RandomPlayer, HumanPlayer, HeuristicPlayer, LookAheadHeuristicPlayer, MCTSPlayer, MCTSHeuristicPlayer, MCTSEvalPlayer\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdl_players\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CNNPlayer\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdl_players_v1\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CNNPlayer_v1\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mrandom\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'dl_players'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../onitama/')\n",
    "from trainer import RegularDataTrainer\n",
    "from dl_players_v3 import CNNPlayer_v3\n",
    "import numpy as np\n",
    "from livelossplot import PlotLossesKeras\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb9180a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def action_to_one_hot(action, shape=(5, 5, 52)):\n",
    "    \"\"\"\n",
    "    Convertit une action [col, ligne, action_id] en one-hot tensor\n",
    "    \n",
    "    Args:\n",
    "        action: [col, ligne, action_id] ou liste d'actions (batch)\n",
    "        shape: (height, width, n_actions)\n",
    "        \n",
    "    Returns:\n",
    "        one_hot: (5, 5, 52) ou (batch, 5, 5, 52)\n",
    "    \"\"\"\n",
    "    if isinstance(action, list) and len(action) == 3:\n",
    "        # Une seule action\n",
    "        col, ligne, action_id = action\n",
    "        one_hot = np.zeros(shape, dtype=np.float32)\n",
    "        one_hot[col, ligne, action_id] = 1.0\n",
    "        return one_hot\n",
    "    else:\n",
    "        # Batch d'actions\n",
    "        batch_size = len(action)\n",
    "        one_hot_batch = np.zeros((batch_size, *shape), dtype=np.float32)\n",
    "        \n",
    "        for i, act in enumerate(action):\n",
    "            col, ligne, action_id = act\n",
    "            one_hot_batch[i, col, ligne, action_id] = 1.0\n",
    "        \n",
    "        return one_hot_batch\n",
    "\n",
    "def flat_index_to_action(flat_index):\n",
    "    \"\"\"\n",
    "    Convertit index flat [0, 1299] en [col, ligne, move_id]\n",
    "    \"\"\"\n",
    "    col = flat_index // (5 * 52)\n",
    "    ligne = (flat_index // 52) % 5\n",
    "    move_id = flat_index % 52\n",
    "    return col, ligne, move_id\n",
    "\n",
    "\n",
    "def decode_flat_policy(flat_policy):\n",
    "    \"\"\"\n",
    "    Décode un vecteur aplati (1300,) en [col, ligne, move_id]\n",
    "    \n",
    "    Args:\n",
    "        flat_policy: array de shape (1300,) - one-hot ou probabilités\n",
    "        \n",
    "    Returns:\n",
    "        action: [col, ligne, move_id]\n",
    "    \"\"\"\n",
    "    # 1. Trouver l'index du maximum (ou du 1.0 si one-hot)\n",
    "    best_index = np.argmax(flat_policy)\n",
    "    \n",
    "    # 2. Décoder l'index\n",
    "    col = best_index // (5 * 52)\n",
    "    ligne = (best_index // 52) % 5\n",
    "    move_id = best_index % 52\n",
    "    \n",
    "    return [int(col), int(ligne), int(move_id)]\n",
    "\n",
    "def old_one_hot_to_action(action, verbose=False):\n",
    "    \"\"\"\n",
    "    Convertit un one-hot tensor en action [col, ligne, move_id]\n",
    "    \n",
    "    Args:\n",
    "        action: (5, 5, 52) ou (batch, 5, 5, 52)\n",
    "        verbose: afficher les détails\n",
    "        \n",
    "    Returns:\n",
    "        (col, ligne, move_id) ou liste de (col, ligne, move_id)\n",
    "    \"\"\"\n",
    "    action = np.array(action)\n",
    "    \n",
    "    # Déterminer si c'est un batch ou une action seule\n",
    "    if action.ndim == 3:\n",
    "        # Une seule action (5, 5, 52)\n",
    "        flat_logits = action.reshape(-1)\n",
    "        \n",
    "        exp_logits = np.exp(flat_logits - np.max(flat_logits))\n",
    "        probabilities = exp_logits / exp_logits.sum()\n",
    "        \n",
    "        best_flat = np.argmax(probabilities)\n",
    "        best_col, best_ligne, best_move_id = flat_index_to_action(best_flat)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"Probabilités : {probabilities.shape}, sum={probabilities.sum():.3f}\")\n",
    "            print(f\"Meilleure action : [{best_col}, {best_ligne}, {best_move_id}]\")\n",
    "            print(f\"Probabilité : {probabilities[best_flat]:.4f}\")\n",
    "        \n",
    "        return (best_col, best_ligne, best_move_id)\n",
    "    \n",
    "    elif action.ndim == 4:\n",
    "        # Batch d'actions (batch, 5, 5, 52)\n",
    "        batch_size = action.shape[0]\n",
    "        results = []\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            flat_logits = action[i].reshape(-1)\n",
    "            \n",
    "            exp_logits = np.exp(flat_logits - np.max(flat_logits))\n",
    "            probabilities = exp_logits / exp_logits.sum()\n",
    "            \n",
    "            best_flat = np.argmax(probabilities)\n",
    "            best_col, best_ligne, best_move_id = flat_index_to_action(best_flat)\n",
    "            \n",
    "            if verbose:\n",
    "                print(f\"[{i}] Probabilités : {probabilities.shape}, sum={probabilities.sum():.3f}\")\n",
    "                print(f\"[{i}] Meilleure action : [{best_col}, {best_ligne}, {best_move_id}]\")\n",
    "                print(f\"[{i}] Probabilité : {probabilities[best_flat]:.4f}\")\n",
    "            \n",
    "            results.append((best_col, best_ligne, best_move_id))\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Action doit avoir 3 ou 4 dimensions, reçu {action.ndim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20fac2fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ../data/training-data-heuristic-vs-laheuristic2-states.pkl loaded !\n",
      "File ../data/training-data-heuristic-vs-laheuristic2-actions.pkl loaded !\n",
      "File ../data/training-data-heuristic-vs-laheuristic3-2-states.pkl loaded !\n",
      "File ../data/training-data-heuristic-vs-laheuristic3-2-actions.pkl loaded !\n",
      "File ../data/training-data-heuristic-vs-laheuristic3-states.pkl loaded !\n",
      "File ../data/training-data-heuristic-vs-laheuristic3-actions.pkl loaded !\n",
      "File ../data/training-data-laheuristic2-vs-laheuristic3-states.pkl loaded !\n",
      "File ../data/training-data-laheuristic2-vs-laheuristic3-actions.pkl loaded !\n",
      "File ../data/training-data-random-vs-laheuristic3-states.pkl loaded !\n",
      "File ../data/training-data-random-vs-laheuristic3-actions.pkl loaded !\n",
      "\n",
      "\n",
      "Total :\n",
      "226287 states\n",
      "226287 policies\n",
      "(226287, 10, 5, 5)\n",
      "(226287, 5, 5, 10)\n"
     ]
    }
   ],
   "source": [
    "#Récupération des données\n",
    "\n",
    "folder_data = \"../data/\"\n",
    "\n",
    "states_files = [\n",
    "    'training-data-heuristic-vs-laheuristic2-states.pkl',\n",
    "    'training-data-heuristic-vs-laheuristic3-2-states.pkl',\n",
    "    'training-data-heuristic-vs-laheuristic3-states.pkl',\n",
    "    'training-data-laheuristic2-vs-laheuristic3-states.pkl',\n",
    "    'training-data-random-vs-laheuristic3-states.pkl'\n",
    "]\n",
    "\n",
    "policy_files = [\n",
    "    'training-data-heuristic-vs-laheuristic2-actions.pkl',\n",
    "    'training-data-heuristic-vs-laheuristic3-2-actions.pkl',\n",
    "    'training-data-heuristic-vs-laheuristic3-actions.pkl',\n",
    "    'training-data-laheuristic2-vs-laheuristic3-actions.pkl',\n",
    "    'training-data-random-vs-laheuristic3-actions.pkl'\n",
    "]\n",
    "\n",
    "states = []\n",
    "policies = []\n",
    "\n",
    "for i in range(len(states_files)):\n",
    "    filename_states = folder_data+states_files[i]\n",
    "    filename_policies = folder_data+policy_files[i]\n",
    "    states += RegularDataTrainer.getTrainedData(filepath=filename_states)\n",
    "    policies += RegularDataTrainer.getTrainedData(filepath=filename_policies)\n",
    "    print(f\"File {filename_states} loaded !\")\n",
    "    print(f\"File {filename_policies} loaded !\")\n",
    "\n",
    "print(\"\\n\\nTotal :\")\n",
    "print(f\"{len(states)} states\")\n",
    "print(f\"{len(policies)} policies\")\n",
    "\n",
    "states = np.array(states)\n",
    "print(states.shape)\n",
    "\n",
    "#On est en (10, 5, 5) le réseau attend du (5, 5, 10) il faut transposer\n",
    "states = np.transpose(states, (0, 2, 3, 1))\n",
    "print(states.shape) #Maintenant on est bien (en 5,5,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd66cd9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(226287, 1300)\n"
     ]
    }
   ],
   "source": [
    "#On applique one Hot Encoder sur les actions (policies)\n",
    "policies = action_to_one_hot(policies)\n",
    "\n",
    "#Aplatir pour correspondre à la sortie du modèle\n",
    "policies = policies.reshape(-1, 5 * 5 * 52)  # (batch, 1300)\n",
    "\n",
    "print(policies.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b990f88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gelé 7 layers de la tête de valeur\n",
      "Modèle compilé pour entraînement supervisé (policy seulement, label_smoothing=0.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lgerard/python/onitama-rl/.venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:797: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 102 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "network = CNNPlayer()\n",
    "#network.compile_for_supervised_policy(learning_rate=0.001)\n",
    "network.load_weights(\"../saved-models/CNNPlayer-withdropout-weights.weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff5bd377",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(states)\n",
    "y_policy = policies\n",
    "y_value = np.zeros((len(x_train), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93ed3934",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_action(network, state, deterministic=True, valid_actions_mask=None):\n",
    "    \"\"\"\n",
    "    Prédit une action à partir d'un état\n",
    "    \n",
    "    Args:\n",
    "        network: Le réseau de neurones\n",
    "        state: (5, 5, 10) - un état (sans batch dimension)\n",
    "        deterministic: Si True, prend l'action avec le score max\n",
    "                      Si False, échantillonne selon les probabilités\n",
    "        valid_actions_mask: (5, 5, 52) optionnel - masque des actions valides\n",
    "        \n",
    "    Returns:\n",
    "        action: [col, ligne, move_id]\n",
    "        probability: probabilité de cette action\n",
    "    \"\"\"\n",
    "    # 1. Ajouter la dimension batch si nécessaire\n",
    "    if len(state.shape) == 3:\n",
    "        state_batch = np.expand_dims(state, axis=0)  # (1, 5, 5, 10)\n",
    "    else:\n",
    "        state_batch = state\n",
    "    \n",
    "    # 2. Prédiction\n",
    "    policy_logits, value = network.predict(state_batch, training=False)\n",
    "    \n",
    "    # 3. Retirer la dimension batch\n",
    "    policy_logits = policy_logits.numpy()\n",
    "    policy_logits = policy_logits[0]  # (5, 5, 52)\n",
    "    value = value[0, 0]  # Scalar\n",
    "    \n",
    "    # 4. Masquer les actions invalides (optionnel mais IMPORTANT)\n",
    "    if valid_actions_mask is not None:\n",
    "        large_negative = -1e9\n",
    "        masked_logits = np.where(\n",
    "            valid_actions_mask,\n",
    "            policy_logits,\n",
    "            large_negative\n",
    "        )\n",
    "    else:\n",
    "        masked_logits = policy_logits\n",
    "    \n",
    "    # 5. Aplatir en (1300,) pour faciliter le traitement\n",
    "    flat_logits = masked_logits.reshape(-1)  # (5*5*52 = 1300,)\n",
    "    \n",
    "    # 6. Convertir en probabilités avec softmax\n",
    "    flat_probs = softmax(flat_logits)\n",
    "    \n",
    "    # 7. Sélectionner l'action\n",
    "    if deterministic:\n",
    "        # Prendre l'action avec la probabilité max\n",
    "        best_index = np.argmax(flat_probs)\n",
    "    else:\n",
    "        # Échantillonner selon les probabilités\n",
    "        best_index = np.random.choice(len(flat_probs), p=flat_probs)\n",
    "    \n",
    "    # 8. Décoder l'index en [col, ligne, move_id]\n",
    "    col = best_index // (5 * 52)\n",
    "    ligne = (best_index // 52) % 5\n",
    "    move_id = best_index % 52\n",
    "    \n",
    "    action = [int(col), int(ligne), int(move_id)]\n",
    "    probability = flat_probs[best_index]\n",
    "    \n",
    "    return action, probability, value\n",
    "\n",
    "\n",
    "def softmax(x):\n",
    "    \"\"\"Calcule le softmax de manière stable numériquement\"\"\"\n",
    "    exp_x = np.exp(x - np.max(x))  # Soustraire le max pour stabilité\n",
    "    return exp_x / exp_x.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e87ec046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------\n",
      "État: (5, 5, 10)\n",
      "Action prédite: [0, 4, 42]\n",
      "  → Colonne: 0\n",
      "  → Ligne: 4\n",
      "  → Mouvement: 42\n",
      "Probabilité: 0.6359\n",
      "[0, 4, 42]\n",
      "---------------------\n",
      "État: (5, 5, 10)\n",
      "Action prédite: [1, 3, 46]\n",
      "  → Colonne: 1\n",
      "  → Ligne: 3\n",
      "  → Mouvement: 46\n",
      "Probabilité: 0.1833\n",
      "[4, 4, 30]\n",
      "---------------------\n",
      "État: (5, 5, 10)\n",
      "Action prédite: [1, 4, 46]\n",
      "  → Colonne: 1\n",
      "  → Ligne: 4\n",
      "  → Mouvement: 46\n",
      "Probabilité: 0.9439\n",
      "[1, 4, 46]\n",
      "---------------------\n",
      "État: (5, 5, 10)\n",
      "Action prédite: [0, 4, 50]\n",
      "  → Colonne: 0\n",
      "  → Ligne: 4\n",
      "  → Mouvement: 50\n",
      "Probabilité: 0.2670\n",
      "[2, 4, 50]\n",
      "---------------------\n",
      "État: (5, 5, 10)\n",
      "Action prédite: [3, 3, 29]\n",
      "  → Colonne: 3\n",
      "  → Ligne: 3\n",
      "  → Mouvement: 29\n",
      "Probabilité: 0.5322\n",
      "[3, 3, 29]\n",
      "---------------------\n",
      "État: (5, 5, 10)\n",
      "Action prédite: [0, 4, 19]\n",
      "  → Colonne: 0\n",
      "  → Ligne: 4\n",
      "  → Mouvement: 19\n",
      "Probabilité: 0.4079\n",
      "[0, 4, 19]\n",
      "---------------------\n",
      "État: (5, 5, 10)\n",
      "Action prédite: [1, 3, 49]\n",
      "  → Colonne: 1\n",
      "  → Ligne: 3\n",
      "  → Mouvement: 49\n",
      "Probabilité: 0.4759\n",
      "[1, 3, 49]\n",
      "---------------------\n",
      "État: (5, 5, 10)\n",
      "Action prédite: [2, 3, 29]\n",
      "  → Colonne: 2\n",
      "  → Ligne: 3\n",
      "  → Mouvement: 29\n",
      "Probabilité: 0.2180\n",
      "[1, 4, 29]\n",
      "---------------------\n",
      "État: (5, 5, 10)\n",
      "Action prédite: [2, 3, 34]\n",
      "  → Colonne: 2\n",
      "  → Ligne: 3\n",
      "  → Mouvement: 34\n",
      "Probabilité: 0.5869\n",
      "[2, 3, 34]\n",
      "---------------------\n",
      "État: (5, 5, 10)\n",
      "Action prédite: [2, 2, 0]\n",
      "  → Colonne: 2\n",
      "  → Ligne: 2\n",
      "  → Mouvement: 0\n",
      "Probabilité: 0.7420\n",
      "[2, 2, 0]\n"
     ]
    }
   ],
   "source": [
    "#Vérification des prédictions pour les premiers états\n",
    "\n",
    "for i in range(10):\n",
    "    # Prédire l'action (déterministe)\n",
    "    state = x_train[i]\n",
    "    action_reelle = y_policy[i]\n",
    "    action, prob, value = predict_action(network, state, deterministic=True)\n",
    "\n",
    "    print(\"---------------------\")\n",
    "    print(f\"État: {state.shape}\")\n",
    "    print(f\"Action prédite: {action}\")\n",
    "    print(f\"  → Colonne: {action[0]}\")\n",
    "    print(f\"  → Ligne: {action[1]}\")\n",
    "    print(f\"  → Mouvement: {action[2]}\")\n",
    "    print(f\"Probabilité: {prob:.4f}\")\n",
    "\n",
    "    print(decode_flat_policy(action_reelle))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
